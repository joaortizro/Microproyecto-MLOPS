{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968cfc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando Random Forest...\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.44      0.59      5756\n",
      "           1       0.84      0.98      0.91     17710\n",
      "\n",
      "    accuracy                           0.85     23466\n",
      "   macro avg       0.86      0.71      0.75     23466\n",
      "weighted avg       0.85      0.85      0.83     23466\n",
      "\n",
      "Modelo entrenado exitosamente.\n",
      "\n",
      "--- Simulando Predicción en Producción ---\n",
      "   Predicción (1=Satisfecho 0=No satisfecho)  Probabilidad\n",
      "0                                          0         0.100\n",
      "1                                          0         0.160\n",
      "2                                          0         0.135\n",
      "3                                          1         0.945\n",
      "4                                          0         0.225\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Dict, Tuple, Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "class OlistSatisfactionModel:\n",
    "    \"\"\"\n",
    "    Pipeline para predecir satisfacción del cliente en Olist.\n",
    "\n",
    "    Enfoque :\n",
    "    - y (target) se construye explícitamente con make_target()\n",
    "    - X (features) se construye explícitamente con build_features()      \n",
    "    Ventajas:\n",
    "    - Evita leakage por diseño (no hay drops largos: simplemente no incluimos lo prohibido).\n",
    "    - Es fácil ver qué entra al modelo (X) y qué se predice (y).\n",
    "    - Si el dataset trae columnas nuevas, NO entran automáticamente al modelo.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_estimators: int = 200, random_state: int = 42, n_jobs: int = -1) -> None:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_estimators : int\n",
    "            Número de árboles para RandomForest.\n",
    "        random_state : int\n",
    "            Semilla de reproducibilidad.\n",
    "        n_jobs : int\n",
    "            Paralelización (-1 usa todos los cores).\n",
    "        \"\"\"\n",
    "        self.model: Optional[RandomForestClassifier] = None\n",
    "\n",
    "        # Metadata necesaria para inferencia consistente\n",
    "        self.model_columns: Optional[pd.Index] = None\n",
    "        self.numeric_means: Optional[pd.Series] = None\n",
    "        self.freight_median_: Optional[float] = None\n",
    "\n",
    "        self.n_estimators = n_estimators\n",
    "        self.random_state = random_state\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # 1) Carga de datos \n",
    "    # ---------------------------------------------------------------------\n",
    "    def load_raw_data(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Descarga el dataset de Olist vía kagglehub y realiza el merge principal\n",
    "        para obtener un DataFrame unificado.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            DataFrame unificado (a nivel item dentro de order).\n",
    "        \"\"\"\n",
    "        #print(\"Descargando/Cargando datos...\")\n",
    "        #path = kagglehub.dataset_download(\"olistbr/brazilian-ecommerce\")\n",
    "\n",
    "        #data: Dict[str, pd.DataFrame] = {}\n",
    "        #for file in os.listdir(path):\n",
    "        #    if file.endswith(\".csv\"):\n",
    "        #        key = file.split(\".\")[0]\n",
    "        #        data[key] = pd.read_csv(os.path.join(path, file))\n",
    "\n",
    "        #df = (\n",
    "        #    data[\"olist_orders_dataset\"]\n",
    "        #    .merge(data[\"olist_order_reviews_dataset\"], on=\"order_id\", how=\"left\")\n",
    "        #    .merge(data[\"olist_order_payments_dataset\"], on=\"order_id\", how=\"left\")\n",
    "        #    .merge(data[\"olist_customers_dataset\"], on=\"customer_id\", how=\"left\")\n",
    "        #    .merge(data[\"olist_order_items_dataset\"], on=\"order_id\", how=\"left\")\n",
    "        #    .merge(data[\"olist_products_dataset\"], on=\"product_id\", how=\"left\")\n",
    "        #    .merge(data[\"olist_sellers_dataset\"], on=\"seller_id\", how=\"left\")\n",
    "        #)\n",
    "        dataset=\"dsunified.csv\"\n",
    "        df= pd.read_csv(f'data/{dataset}')\n",
    "        return df\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # 2) Target explícito (Y)\n",
    "    # ---------------------------------------------------------------------\n",
    "    def make_target(self, df: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Construye target (y) desde review_score.\n",
    "\n",
    "        Definición:\n",
    "        - y = 1 si review_score >= 4\n",
    "        - y = 0 si review_score < 4\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            Debe contener la columna 'review_score' (solo training).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.Series\n",
    "            Vector y de 0/1.\n",
    "        \"\"\"\n",
    "        if \"review_score\" not in df.columns:\n",
    "            raise KeyError(\"Training requiere 'review_score' para construir el target.\")\n",
    "        return (df[\"review_score\"] >= 4).astype(int)\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # 3) features (X) explícito (whitelist)\n",
    "    # ---------------------------------------------------------------------\n",
    "    def build_features(self, df: pd.DataFrame, is_training: bool) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Construye features (X) de forma explícita (whitelist).\n",
    "        Solo incluye:\n",
    "        - features temporales (deltas y componentes)\n",
    "        - features de precio/flete/revenue\n",
    "        - volumen de producto\n",
    "        - algunas categóricas de baja cardinalidad (state, payment_type, product_category_name)\n",
    "\n",
    "        IMPORTANT:\n",
    "        - No usa ni incluye review_score en X (evita leakage).\n",
    "        - Aprende un umbral fijo (freight_median_) en training y lo reutiliza en inference.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            DataFrame crudo (merge) o batch nuevo con columnas equivalentes.\n",
    "        is_training : bool\n",
    "            True en entrenamiento, False en inferencia.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            DataFrame X con features listas para preprocesamiento.\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "\n",
    "        # --- Parseo de fechas mínimas necesarias ---\n",
    "        if \"order_purchase_timestamp\" not in df.columns:\n",
    "            raise KeyError(\"Falta 'order_purchase_timestamp' (requerida).\")\n",
    "\n",
    "        df[\"order_purchase_timestamp\"] = pd.to_datetime(df[\"order_purchase_timestamp\"], errors=\"coerce\")\n",
    "\n",
    "        date_cols = [\n",
    "            \"order_approved_at\",\n",
    "            \"order_delivered_carrier_date\",\n",
    "            \"order_delivered_customer_date\",\n",
    "            \"order_estimated_delivery_date\",\n",
    "            \"shipping_limit_date\",\n",
    "        ]\n",
    "        for c in date_cols:\n",
    "            if c in df.columns:\n",
    "                df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "\n",
    "        base = df[\"order_purchase_timestamp\"]\n",
    "\n",
    "        # --- X explícito (solo lo que queremos que exista) ---\n",
    "        X = pd.DataFrame(index=df.index)\n",
    "\n",
    "        # 1) Deltas (days)\n",
    "        def delta_days(col: str) -> pd.Series:\n",
    "            if col not in df.columns:\n",
    "                return pd.Series(np.nan, index=df.index)\n",
    "            return (df[col] - base).dt.days\n",
    "\n",
    "        X[\"delta_approved\"] = delta_days(\"order_approved_at\")\n",
    "        X[\"delta_estimated_delivery\"] = delta_days(\"order_estimated_delivery_date\")\n",
    "        X[\"delta_shipping_limit\"] = delta_days(\"shipping_limit_date\")\n",
    "        X[\"delta_delivered_customer\"] = delta_days(\"order_delivered_customer_date\")\n",
    "        X[\"delta_delivered_carrier\"] = delta_days(\"order_delivered_carrier_date\")\n",
    "\n",
    "        # 2) Componentes fecha\n",
    "        X[\"purchase_year\"] = base.dt.year\n",
    "        X[\"purchase_month\"] = base.dt.month\n",
    "        X[\"purchase_day\"] = base.dt.day\n",
    "\n",
    "        # 3) Volumen producto (si existen dimensiones)\n",
    "        dims = {\"product_length_cm\", \"product_height_cm\", \"product_width_cm\"}\n",
    "        if dims.issubset(df.columns):\n",
    "            X[\"product_cubic_volume\"] = (\n",
    "                df[\"product_length_cm\"] * df[\"product_height_cm\"] * df[\"product_width_cm\"]\n",
    "            )\n",
    "        else:\n",
    "            X[\"product_cubic_volume\"] = np.nan\n",
    "\n",
    "        # 4) Precio/Flete/Revenue (si existen columnas)\n",
    "        required_pf = {\"price\", \"freight_value\"}\n",
    "        if required_pf.issubset(df.columns):\n",
    "            # Evita división por 0: si price=0 -> NaN\n",
    "            price = df[\"price\"].replace(0, np.nan)\n",
    "\n",
    "            X[\"freight_percentage\"] = df[\"freight_value\"] / price\n",
    "            X[\"net_revenue\"] = df[\"price\"] - df[\"freight_value\"]\n",
    "            X[\"revenue_per_order\"] = df[\"price\"] + df[\"freight_value\"]\n",
    "        else:\n",
    "            X[\"freight_percentage\"] = np.nan\n",
    "            X[\"net_revenue\"] = np.nan\n",
    "            X[\"revenue_per_order\"] = np.nan\n",
    "\n",
    "        # 5) Flag de freight alto con umbral fijo aprendido\n",
    "        if is_training:\n",
    "            self.freight_median_ = float(pd.Series(X[\"freight_percentage\"]).median(skipna=True))\n",
    "\n",
    "        if self.freight_median_ is None:\n",
    "            raise RuntimeError(\"freight_median_ no inicializado. Entrena el modelo primero.\")\n",
    "\n",
    "        X[\"is_high_freight\"] = (X[\"freight_percentage\"] > self.freight_median_).astype(int)\n",
    "\n",
    "        # 6) Categóricas (baja cardinalidad y razonables en prod)\n",
    "        # Nota: evitar customer_city/seller_city por cardinalidad.\n",
    "        cat_allow = [\n",
    "            \"customer_state\",\n",
    "            \"seller_state\",\n",
    "            \"payment_type\",\n",
    "            \"product_category_name\",\n",
    "        ]\n",
    "        for col in cat_allow:\n",
    "            X[col] = df[col] if col in df.columns else np.nan\n",
    "\n",
    "        return X\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # 4) Preprocess: imputación + one-hot + alineación\n",
    "    # ---------------------------------------------------------------------\n",
    "    def preprocess(self, X: pd.DataFrame, is_training: bool) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Preprocesa X para el modelo:\n",
    "        - Imputa numéricos con medias aprendidas en training.\n",
    "        - En inferencia, rellena categóricos faltantes con 'Unknown'.\n",
    "        - One-hot encoding con pd.get_dummies.\n",
    "        - En inferencia, reindexa para coincidir con columnas vistas en training.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            Features construidas por build_features().\n",
    "        is_training : bool\n",
    "            True para aprender estadísticas y columnas; False para aplicar.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Matriz final model-ready.\n",
    "        \"\"\"\n",
    "        X = X.copy()\n",
    "\n",
    "        # 1) Medias numéricas (training) + imputación (train/infer)\n",
    "        num_cols = X.select_dtypes(include=[\"number\", \"bool\"]).columns\n",
    "        if is_training:\n",
    "            self.numeric_means = X[num_cols].mean(numeric_only=True)\n",
    "\n",
    "        if self.numeric_means is None:\n",
    "            raise RuntimeError(\"numeric_means no inicializado. Entrena el modelo primero.\")\n",
    "\n",
    "        cols_to_fill = [c for c in self.numeric_means.index if c in X.columns]\n",
    "        if cols_to_fill:\n",
    "            X[cols_to_fill] = X[cols_to_fill].fillna(self.numeric_means[cols_to_fill])\n",
    "\n",
    "        #2) Categóricas: Imputación consistente \"Unknown\"\n",
    "        cat_cols = X.select_dtypes(include=[\"object\", \"string\"]).columns\n",
    "        if len(cat_cols) > 0:\n",
    "            X[cat_cols] = X[cat_cols].fillna(\"Unknown\")\n",
    "\n",
    "        # Limpieza final de filas en training (solo si quedan nulos rebeldes)\n",
    "        if is_training:\n",
    "            # En entrenamiento: Queremos datos puros.\n",
    "            # Si algo falló en la imputación y sigue siendo nulo, lo borramos.\n",
    "            # No queremos que el modelo aprenda de datos corruptos.\n",
    "            X = X.dropna()\n",
    "        else:\n",
    "            # En inferencia: PROHIBIDO BORRAR FILAS.\n",
    "            # Si queda algún nulo rebelde (ej. una columna numérica que era \n",
    "            # 100% nula en el training y no tiene media), lo rellenamos con 0.\n",
    "            # Esto evita que Sklearn falle (ValueError) y garantiza una respuesta.\n",
    "            X = X.fillna(0)\n",
    "            \n",
    "        # 3) One-hot\n",
    "        X_enc = pd.get_dummies(X)\n",
    "\n",
    "        if is_training:\n",
    "            self.model_columns = X_enc.columns\n",
    "\n",
    "        if self.model_columns is None:\n",
    "            raise RuntimeError(\"model_columns no inicializado. Entrena el modelo primero.\")\n",
    "\n",
    "        if not is_training:\n",
    "            X_enc = X_enc.reindex(columns=self.model_columns, fill_value=0)\n",
    "\n",
    "        return X_enc\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # 5) Train / Predict\n",
    "    # ---------------------------------------------------------------------\n",
    "    def train(self, test_size: float = 0.2) -> None:\n",
    "        \"\"\"\n",
    "        Entrena RandomForest usando separación explícita X/y.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        test_size : float\n",
    "            Proporción de test.\n",
    "        \"\"\"\n",
    "        df_raw = self.load_raw_data()\n",
    "\n",
    "        # y explícito\n",
    "        y = self.make_target(df_raw)\n",
    "\n",
    "        # X explícito\n",
    "        X = self.build_features(df_raw, is_training=True)\n",
    "\n",
    "        # Transformación final\n",
    "        X_final = self.preprocess(X, is_training=True)\n",
    "\n",
    "        # Alinear y con X_final (por el dropna del training en preprocess)\n",
    "        # Asegura mismos índices\n",
    "        y = y.loc[X_final.index]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_final, y, test_size=test_size, random_state=self.random_state, stratify=y\n",
    "        )\n",
    "\n",
    "        print(\"Entrenando Random Forest...\")\n",
    "        self.model = RandomForestClassifier(\n",
    "            n_estimators=self.n_estimators,\n",
    "            random_state=self.random_state,\n",
    "            n_jobs=self.n_jobs,\n",
    "        )\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        print(\"Reporte de Clasificación:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(\"Modelo entrenado exitosamente.\")\n",
    "\n",
    "    def predict(self, new_data: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Predice clase y probabilidad para datos nuevos.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        new_data : pd.DataFrame\n",
    "            DataFrame crudo. En producción real no incluirá review_score.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, np.ndarray]\n",
    "            (preds, probs)\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"El modelo no ha sido entrenado. Ejecuta .train() primero.\")\n",
    "\n",
    "        X = self.build_features(new_data, is_training=False)\n",
    "        X_final = self.preprocess(X, is_training=False)\n",
    "\n",
    "        preds = self.model.predict(X_final)\n",
    "        probs = self.model.predict_proba(X_final)[:, 1]\n",
    "        return preds, probs\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # 6) Save / Load Model\n",
    "    # ---------------------------------------------------------------------\n",
    "    def save(self, path: str) -> None:\n",
    "        \"\"\"\n",
    "        Guarda el modelo y metadata necesaria para inferencia.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path : str\n",
    "            Ruta del archivo joblib.\n",
    "        \"\"\"\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"model_columns\": self.model_columns,\n",
    "            \"numeric_means\": self.numeric_means,\n",
    "            \"freight_median_\": self.freight_median_,\n",
    "            \"n_estimators\": self.n_estimators,\n",
    "            \"random_state\": self.random_state,\n",
    "            \"n_jobs\": self.n_jobs,\n",
    "        }\n",
    "        joblib.dump(payload, path)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path: str) -> \"OlistSatisfactionModel\":\n",
    "        \"\"\"\n",
    "        Carga un pipeline guardado.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path : str\n",
    "            Ruta al joblib guardado.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        OlistSatisfactionModel\n",
    "            Instancia lista para inferencia.\n",
    "        \"\"\"\n",
    "        payload = joblib.load(path)\n",
    "        obj = cls(\n",
    "            n_estimators=payload.get(\"n_estimators\", 200),\n",
    "            random_state=payload.get(\"random_state\", 42),\n",
    "            n_jobs=payload.get(\"n_jobs\", -1),\n",
    "        )\n",
    "        obj.model = payload[\"model\"]\n",
    "        obj.model_columns = payload[\"model_columns\"]\n",
    "        obj.numeric_means = payload[\"numeric_means\"]\n",
    "        obj.freight_median_ = payload[\"freight_median_\"]\n",
    "        return obj\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = OlistSatisfactionModel(n_estimators=200)\n",
    "\n",
    "    # 1) Entrenar\n",
    "    pipeline.train(test_size=0.2)\n",
    "\n",
    "    # 2) Simular predicción con una muestra\n",
    "    print(\"\\n--- Simulando Predicción en Producción ---\")\n",
    "    df_raw = pipeline.load_raw_data().sample(5, random_state=42)\n",
    "\n",
    "    # En producción real review_score no existe; si aparece lo removemos (no afecta X igualmente)\n",
    "    if \"review_score\" in df_raw.columns:\n",
    "        df_raw = df_raw.drop(columns=[\"review_score\"])\n",
    "\n",
    "    preds, probs = pipeline.predict(df_raw)\n",
    "    results = pd.DataFrame({\n",
    "        \"Predicción (1=Satisfecho 0=No satisfecho)\": preds,\n",
    "        \"Probabilidad\": probs\n",
    "    })\n",
    "    print(results)\n",
    "\n",
    "    # 3) Guardar / cargar\n",
    "    #os.makedirs(\"output\", exist_ok=True)\n",
    "    #model_path = \"output/olist_rf_claro.joblib\"\n",
    "    #pipeline.save(model_path)\n",
    "\n",
    "    #loaded = OlistSatisfactionModel.load(model_path)\n",
    "    #preds2, probs2 = loaded.predict(df_raw)\n",
    "    #print(\"\\nOK tras cargar:\", preds2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521df0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
